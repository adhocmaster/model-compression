{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10e0199-db90-4ed6-a1a3-4e38e8225b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (relu2): ReLU()\n",
      "  (relu3): ReLU()\n",
      "  (relu4): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "\n",
    "from nni_assets.compression.mnist_model import TorchModel, trainer, evaluator, device\n",
    "\n",
    "# define the model\n",
    "model = TorchModel().to(device)\n",
    "\n",
    "# show the model structure, note that pruner will wrap the model layer.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2423a718-8374-497a-83cf-9ff38ed8be99",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# pre-train and evaluate the model on MNIST dataset\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     evaluator(model)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\compress39\\lib\\site-packages\\nni_assets\\compression\\mnist_model.py:54\u001b[0m, in \u001b[0;36mtrainer\u001b[1;34m(model, optimizer, criterion)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrainer\u001b[39m(model, optimizer, criterion):\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# training the model\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     55\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     56\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\compress39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\compress39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\compress39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\compress39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\compress39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:142\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    138\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "# define the optimizer and criterion for pre-training\n",
    "\n",
    "optimizer = SGD(model.parameters(), 1e-2)\n",
    "criterion = F.nll_loss\n",
    "\n",
    "# pre-train and evaluate the model on MNIST dataset\n",
    "for epoch in range(3):\n",
    "    trainer(model, optimizer, criterion)\n",
    "    evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e5d1324-f3f0-43dd-a661-1d31615e99d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight: 150\n",
      "conv1.bias: 6\n",
      "conv2.weight: 2400\n",
      "conv2.bias: 16\n",
      "fc1.weight: 30720\n",
      "fc1.bias: 120\n",
      "fc2.weight: 10080\n",
      "fc2.bias: 84\n",
      "fc3.weight: 840\n",
      "fc3.bias: 10\n",
      "total: 44426\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for name, param in model.state_dict().items():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "    total += param.numel()\n",
    "print(f\"total: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f949214a-fc6d-4307-907b-661ac875906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune configs\n",
    "config_list = [{\n",
    "    'op_types': ['Linear', 'Conv2d'], # types of layers to prune\n",
    "    'exclude_op_names': ['fc3'], # exclude specific layers\n",
    "    'sparse_ratio': 0.3 # mask 30% of the parameters\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c41a0e2-e63d-458d-b961-b982aa4b69ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchModel(\n",
      "  (conv1): Conv2d(\n",
      "    1, 6, kernel_size=(5, 5), stride=(1, 1)\n",
      "    (_nni_wrapper): ModuleWrapper(module=Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)), module_name=conv1)\n",
      "  )\n",
      "  (conv2): Conv2d(\n",
      "    6, 16, kernel_size=(5, 5), stride=(1, 1)\n",
      "    (_nni_wrapper): ModuleWrapper(module=Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)), module_name=conv2)\n",
      "  )\n",
      "  (fc1): Linear(\n",
      "    in_features=256, out_features=120, bias=True\n",
      "    (_nni_wrapper): ModuleWrapper(module=Linear(in_features=256, out_features=120, bias=True), module_name=fc1)\n",
      "  )\n",
      "  (fc2): Linear(\n",
      "    in_features=120, out_features=84, bias=True\n",
      "    (_nni_wrapper): ModuleWrapper(module=Linear(in_features=120, out_features=84, bias=True), module_name=fc2)\n",
      "  )\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (relu2): ReLU()\n",
      "  (relu3): ReLU()\n",
      "  (relu4): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from nni.compression.pruning import L1NormPruner\n",
    "pruner = L1NormPruner(model, config_list)\n",
    "\n",
    "# show the wrapped model structure, `PrunerModuleWrapper` have wrapped the layers that configured in the config_list.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ce4c92-bc60-4516-a29f-e3308b06f19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc2  sparsity :  0.7\n",
      "conv2  sparsity :  0.75\n",
      "fc1  sparsity :  0.7\n",
      "conv1  sparsity :  0.83\n"
     ]
    }
   ],
   "source": [
    "# compress the model and generate the masks\n",
    "_, masks = pruner.compress()\n",
    "# show the masks sparsity\n",
    "for name, mask in masks.items():\n",
    "    print(name, ' sparsity : ', '{:.2}'.format(mask['weight'].sum() / mask['weight'].numel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6372cafd-9052-48c5-b5cd-d4e6b6a46212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-04 14:34:24] \u001b[32mStart to speedup the model...\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mResolve the mask conflict before mask propagate...\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mdim0 sparsity: 0.227273\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n",
      "0 Filter\n",
      "[2024-07-04 14:34:24] \u001b[32mdim0 sparsity: 0.227273\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mInfer module masks...\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate original variables\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate variables for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate variables for call_module: conv1, weight:  0.1667 bias:  0.1667 , output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate variables for call_module: relu1, , output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate variables for call_module: pool1, , output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate variables for call_module: conv2, weight:  0.2500 bias:  0.2500 , output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate variables for call_module: relu2, , output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate variables for call_module: pool2, , output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate variables for call_function: flatten, output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate variables for call_module: fc1, weight:  0.3000 bias:  0.3000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate variables for call_module: relu3, , output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate variables for call_module: fc2, weight:  0.2976 bias:  0.2976 , output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate variables for call_module: relu4, , output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate variables for call_module: fc3, , output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate variables for call_function: log_softmax, output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mPropagate variables for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct sparsity...\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct mask for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct mask for call_module: conv1, weight:  0.1667 bias:  0.1667 , output mask:  0.1667 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct mask for call_module: relu1, , output mask:  0.1667 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct mask for call_module: pool1, , output mask:  0.1667 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct mask for call_module: conv2, weight:  0.2500 bias:  0.2500 , output mask:  0.2500 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct mask for call_module: relu2, , output mask:  0.2500 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct mask for call_module: pool2, , output mask:  0.2500 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct mask for call_function: flatten, output mask:  0.2500 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct mask for call_module: fc1, weight:  0.3000 bias:  0.3000 , output mask:  0.3000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct mask for call_module: relu3, , output mask:  0.3000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct mask for call_module: fc2, weight:  0.2976 bias:  0.2976 , output mask:  0.2976 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct mask for call_module: relu4, , output mask:  0.2976 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct mask for call_module: fc3, , output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct mask for call_function: log_softmax, output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate direct mask for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect sparsity...\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect mask for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect mask for call_function: log_softmax, output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect mask for call_module: fc3, , output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect mask for call_module: relu4, , output mask:  0.2976 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect mask for call_module: fc2, weight:  0.5083 bias:  0.2976 , output mask:  0.2976 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect mask for call_module: relu3, , output mask:  0.3000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect mask for call_module: fc1, weight:  0.4750 bias:  0.3000 , output mask:  0.3000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect mask for call_function: flatten, output mask:  0.2500 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect mask for call_module: pool2, , output mask:  0.2500 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect mask for call_module: relu2, , output mask:  0.3301 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect mask for call_module: conv2, weight:  0.3750 bias:  0.2500 , output mask:  0.3301 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect mask for call_module: pool1, , output mask:  0.1667 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect mask for call_module: relu1, , output mask:  0.2509 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect mask for call_module: conv1, weight:  0.1667 bias:  0.1667 , output mask:  0.2509 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mUpdate indirect mask for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mResolve the mask conflict after mask propagate...\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mdim0 sparsity: 0.227273\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mdim1 sparsity: 0.142857\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n",
      "0 Filter\n",
      "[2024-07-04 14:34:24] \u001b[32mdim0 sparsity: 0.227273\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mdim1 sparsity: 0.142857\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mReplace compressed modules...\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace conv2d with in_channels: 1, out_channels: 5\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace module (name: relu1, op_type: ReLU)\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace module (name: pool1, op_type: MaxPool2d)\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace conv2d with in_channels: 5, out_channels: 12\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace module (name: relu2, op_type: ReLU)\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace module (name: pool2, op_type: MaxPool2d)\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace linear with new in_features: 192, out_features: 84\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace module (name: relu3, op_type: ReLU)\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace linear with new in_features: 84, out_features: 59\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace module (name: relu4, op_type: ReLU)\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace module (name: fc3, op_type: Linear)\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mreplace linear with new in_features: 59, out_features: 10\u001b[0m\n",
      "[2024-07-04 14:34:24] \u001b[32mSpeedup done.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TorchModel(\n",
       "  (conv1): Conv2d(1, 5, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(5, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=84, bias=True)\n",
       "  (fc2): Linear(in_features=84, out_features=59, bias=True)\n",
       "  (fc3): Linear(in_features=59, out_features=10, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (relu2): ReLU()\n",
       "  (relu3): ReLU()\n",
       "  (relu4): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to unwrap the model, if the model is wrapped before speedup\n",
    "pruner.unwrap_model()\n",
    "\n",
    "# speedup the model, for more information about speedup, please refer :doc:`pruning_speedup`.\n",
    "from nni.compression.speedup import ModelSpeedup\n",
    "\n",
    "ModelSpeedup(model, torch.rand(3, 1, 28, 28).to(device), masks).speedup_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2501ec-ab34-4094-99a6-ec54dd02fd60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
